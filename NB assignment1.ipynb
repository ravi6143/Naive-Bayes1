{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2953252d-9584-4420-ac68-c6f554036221",
   "metadata": {},
   "source": [
    "## Question - 1\n",
    "ans - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ed19da-6248-43c5-a2c9-5bc23ce35df8",
   "metadata": {},
   "source": [
    "Bayes' Theorem states that the probability of a hypothesis given some evidence is proportional to the product of the prior probability of the hypothesis and the likelihood of the evidence given the hypothesis, divided by the probability of the evidence.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3352ac-2854-4af9-a0a2-df7501ca8469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9f6e62-fa3f-4e99-a083-032ca022ba4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "762ff15c-d789-40f6-8083-1b6b2ce26465",
   "metadata": {},
   "source": [
    "## Question - 2\n",
    "ans - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680ab32a-e643-4747-a818-d2e70788f897",
   "metadata": {},
   "source": [
    "The theorem is expressed mathematically as:\n",
    "\n",
    "P(A∣B)= P(B∣A)⋅P(A) / P(B)\n",
    "​\n",
    " \n",
    "\n",
    "Where:\n",
    "\n",
    "* P(A∣B) is the probability of hypothesis A given the evidence B (posterior probability).\n",
    "\n",
    "* P(B∣A) is the probability of evidence B given hypothesis A (likelihood).\n",
    "\n",
    "* P(A) is the prior probability of hypothesis A.\n",
    "\n",
    "* P(B) is the probability of evidence B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864f9c2e-b44b-4e3e-bb91-6cb1b9618a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4e1652-1f2c-487d-ad99-ab03f8a96661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b264898-c464-47ef-9bb3-13a2cb773efa",
   "metadata": {},
   "source": [
    "## Question - 3\n",
    "ans - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3973f6dc-e918-42c8-a942-4773097d80ed",
   "metadata": {},
   "source": [
    "Bayes' theorem is used in practice in various fields for making probabilistic predictions, updating beliefs, and performing statistical inference. Here are some practical applications of Bayes' theorem:\n",
    "\n",
    "1. Bayesian Inference:\n",
    "\n",
    "In statistics, Bayes' theorem is used for Bayesian inference. It allows statisticians to update probabilities as new data becomes available. This is particularly useful in fields such as medical research, where hypotheses can be continuously refined based on new evidence.\n",
    "\n",
    "\n",
    "2. Machine Learning:\n",
    "\n",
    "Bayes' theorem is a fundamental concept in Bayesian machine learning. In machine learning, it is applied in Bayesian classifiers, where it helps update the probability of a hypothesis (class label) given the observed data.\n",
    "\n",
    "\n",
    "3. Spam Filtering:\n",
    "\n",
    "Bayes' theorem is used in spam filtering algorithms. It helps calculate the probability that an email is spam given certain features (words, patterns) in the email. Bayesian spam filters continuously update their probabilities based on new examples.\n",
    "\n",
    "\n",
    "4. Medical Diagnosis:\n",
    "\n",
    "In medical diagnosis, Bayes' theorem is used to update the probability of a disease given symptoms or test results. It allows for the incorporation of prior knowledge and the continuous refinement of diagnostic probabilities.\n",
    "\n",
    "\n",
    "5. Financial Modeling:\n",
    "\n",
    "Bayes' theorem is employed in financial modeling, especially for risk assessment and portfolio optimization. It helps update the probability of financial events based on new market information.\n",
    "\n",
    "\n",
    "6. Fault Diagnosis in Engineering:\n",
    "\n",
    "In engineering, Bayes' theorem is used for fault diagnosis in systems. It helps update the probability of different fault scenarios given observed system behavior.\n",
    "\n",
    "\n",
    "7. Natural Language Processing:\n",
    "\n",
    "Bayes' theorem is utilized in natural language processing tasks, such as language modeling and text classification. It helps calculate the probability of a particular word or phrase given the context.\n",
    "\n",
    "\n",
    "8. A/B Testing:\n",
    "\n",
    "In A/B testing scenarios, Bayes' theorem is used to update the probability that a particular version of a webpage or product is more effective based on observed user behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88ce5c8-45a9-42b0-8dae-815d1933f695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c74a2e5-ba15-413a-ad83-38a0e77c57f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "404d9ffb-9d08-4474-9f34-68055c66a5b3",
   "metadata": {},
   "source": [
    "## Question - 4\n",
    "ans - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad2cc40-600b-4cc9-bcd6-651723c2ef79",
   "metadata": {},
   "source": [
    "Bayes' theorem is closely related to conditional probability, and it provides a way to update conditional probabilities based on new evidence. The relationship between Bayes' theorem and conditional probability is fundamental to understanding how beliefs or probabilities about hypotheses can be revised when new information becomes available.\n",
    "\n",
    "Bayes' theorem is mathematically expressed as:\n",
    "\n",
    "P(A∣B)= P(B∣A)⋅P(A) / P(B)\n",
    "​\n",
    " \n",
    "\n",
    "Here's how Bayes' theorem relates to conditional probability:\n",
    "\n",
    "* Conditional Probability P(A∣B):\n",
    "\n",
    "This represents the probability of event A occurring given that event B has occurred. It is the probability of A under the condition that B is true.\n",
    "\n",
    "* Likelihood P(B∣A):\n",
    "\n",
    "This represents the probability of event B occurring given that event A has occurred. It is the probability of B under the condition that A is true.\n",
    "\n",
    "\n",
    "* Prior Probability P(A):\n",
    "\n",
    "This is the initial or prior probability of event A before considering the new evidence B.\n",
    "\n",
    "\n",
    "Posterior Probability P(A∣B):\n",
    "\n",
    "This is the updated probability of event A after taking into account the new evidence B. It is calculated using Bayes' theorem.\n",
    "\n",
    "* Evidence P(B):\n",
    "\n",
    "This is the probability of event B occurring, irrespective of the occurrence of event A. It is the normalization factor in Bayes' theorem and ensures that the posterior probability is a valid probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978275db-dd0f-40e6-8614-381d8b08d356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be4a0b3-1b4a-4064-9ada-4ca767365601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "846f8864-8621-4d2f-8ce1-da51094851f2",
   "metadata": {},
   "source": [
    "## Question - 5\n",
    "ans - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e9d25d-c27c-4311-932c-bae979e96588",
   "metadata": {},
   "source": [
    "The choice of which type of Naive Bayes classifier to use for a given problem depends on the nature of the data and the assumptions that align with the problem's characteristics. There are three main types of Naive Bayes classifiers: Gaussian Naive Bayes, Multinomial Naive Bayes, and Bernoulli Naive Bayes. Here's a guideline on choosing the appropriate type:\n",
    "\n",
    "1. Gaussian Naive Bayes:\n",
    "\n",
    "* Data Type: Continuous data that can be modeled using a Gaussian (normal) distribution.\n",
    "\n",
    "* Example Applications:\n",
    "Natural language processing tasks where features are continuous (e.g., word frequencies).\n",
    "Predictive modeling with continuous features (e.g., sensor data).\n",
    "\n",
    "\n",
    "2. Multinomial Naive Bayes:\n",
    "\n",
    "* Data Type: Discrete data, typically representing counts or frequencies of events.\n",
    "\n",
    "* Example Applications:\n",
    "Text classification tasks where features are word frequencies or term frequencies.\n",
    "Document classification or spam filtering where features are word counts.\n",
    "\n",
    "\n",
    "3. Bernoulli Naive Bayes:\n",
    "\n",
    "* Data Type: Binary or Boolean data, often representing presence or absence of features.\n",
    "\n",
    "* Example Applications:\n",
    "Text classification tasks with binary features (e.g., bag-of-words representation).\n",
    "Document classification where features represent the presence or absence of certain words.\n",
    "\n",
    "\n",
    "## Factors to Consider:\n",
    "\n",
    "1. Nature of Features:\n",
    "\n",
    "Consider the distribution of your features (continuous, discrete, binary) and choose the Naive Bayes classifier that aligns with the nature of your features.\n",
    "\n",
    "\n",
    "2. Assumptions:\n",
    "\n",
    "Each Naive Bayes classifier makes different assumptions about the distribution of features. For example, Gaussian Naive Bayes assumes features are normally distributed.\n",
    "\n",
    "\n",
    "3. Size of Dataset:\n",
    "\n",
    "The size of your dataset can also influence the choice. In practice, if you have a small dataset, a simpler model like Multinomial or Bernoulli Naive Bayes might be more suitable due to fewer parameters.\n",
    "\n",
    "\n",
    "4. Task Requirements:\n",
    "\n",
    "Consider the specific requirements of your classification task. For example, if you are working on text classification, Multinomial or Bernoulli Naive Bayes might be more appropriate.\n",
    "\n",
    "\n",
    "5. Handling Missing Data:\n",
    "\n",
    "Some Naive Bayes classifiers handle missing data more naturally than others. For example, Gaussian Naive Bayes can handle missing values more effectively in continuous data.\n",
    "\n",
    "\n",
    "6. Experimentation:\n",
    "\n",
    "Experiment with different Naive Bayes classifiers and evaluate their performance using cross-validation or other evaluation metrics to determine which one works best for your specific problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c3c7d5-615d-4da3-8643-4b055d018adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274a2500-5684-48ef-bbe0-edcfed5382c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61c78033-f158-4b59-945b-b073cb0f8ff9",
   "metadata": {},
   "source": [
    "## Question - 6\n",
    "ans - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea60b46-6d6b-4db6-8519-3850bdfe51c0",
   "metadata": {},
   "source": [
    "Instances in Class A with features X1=3 and X2=4 are:\n",
    "\n",
    "Class A: X1=3,X2=4X1=3,X2=4X1=3,X2=4\n",
    "\n",
    "Now, let's calculate the probabilities:\n",
    "\n",
    "* For Class A:\n",
    "\n",
    "P(X1 = 3∣A)⋅P(X2=4∣A) ∝ 3/10 * 3/10\n",
    "​\n",
    " \n",
    "There are a total of 10 instances in Class A, and 3 instances with X1 = 3 and 3 instances with X2 = 4.\n",
    "\n",
    "* For Class B:\n",
    "\n",
    "P(X1 = 3∣B)⋅P(X2 = 4∣B)∝ 1/10 * 3/10\n",
    " \n",
    "There are a total of 10 instances in Class B, and 1 instance with X1 = 3 and 3 instances with X2=4.\n",
    "\n",
    "\n",
    "* Now, compare the probabilities:\n",
    "\n",
    "## P(Class A∣X1=3,X2=4) ∝ 3/10 * 3/10\n",
    " \n",
    "## P(Class B∣X1=3,X2=4) ∝ 1/10 * 3/10\n",
    " \n",
    "Since we are only comparing the ratios between classes, we can ignore the proportional constant. The probability is higher for Class A.\n",
    "\n",
    "Therefore, based on the Naive Bayes prediction, the new instance with features X1=3 and X2=4 is more likely to belong to Class A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1c7cbb-e97d-4a04-9d4b-0a6ef2034cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
